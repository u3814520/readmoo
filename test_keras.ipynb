{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced9cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95198"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rating_df = pd.read_csv('./df_star.csv', \n",
    "                        low_memory=False, \n",
    "                        usecols=[\"user_id\", \"ISBN\", \"USERSTAR\",\"BOOKNAME\"]\n",
    "\n",
    "                        )\n",
    "rating_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338365aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95198"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出評論超過兩本書的使用者\n",
    "n_ratings = rating_df['user_id'].value_counts()\n",
    "rating_df = rating_df[rating_df['user_id'].isin(n_ratings[n_ratings >= 2].index)].copy()\n",
    "len(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee48c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg 0.7619004600936995\n"
     ]
    }
   ],
   "source": [
    "# Scaling BTW\n",
    "min_rating = min(rating_df['USERSTAR'])\n",
    "max_rating = max(rating_df['USERSTAR'])\n",
    "rating_df['USERSTAR'] = rating_df[\"USERSTAR\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values.astype(np.float64)\n",
    "\n",
    "AvgRating = np.mean(rating_df['USERSTAR'])\n",
    "print('Avg', AvgRating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c988b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 124 duplicates\n",
      "> 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "duplicates = rating_df.duplicated()\n",
    "if duplicates.sum() > 0:\n",
    "    print('> {} duplicates'.format(duplicates.sum()))\n",
    "    rating_df = rating_df[~duplicates]\n",
    "\n",
    "print('> {} duplicates'.format(rating_df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6949f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>9789571350813</th>\n",
       "      <th>9789573330127</th>\n",
       "      <th>9789573330806</th>\n",
       "      <th>9789573333166</th>\n",
       "      <th>9789579447607</th>\n",
       "      <th>9789866712982</th>\n",
       "      <th>9789866739798</th>\n",
       "      <th>9789866954108</th>\n",
       "      <th>9789866973420</th>\n",
       "      <th>9789867778383</th>\n",
       "      <th>9789868461406</th>\n",
       "      <th>9789868652378</th>\n",
       "      <th>9789868703612</th>\n",
       "      <th>9789868781900</th>\n",
       "      <th>9789869236478</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN     9789571350813  9789573330127  9789573330806  9789573333166  \\\n",
       "user_id                                                               \n",
       "195                NaN            NaN            NaN            NaN   \n",
       "952                NaN            NaN            NaN            NaN   \n",
       "1103               1.0            NaN            NaN            NaN   \n",
       "1314               0.8            NaN            NaN            NaN   \n",
       "1492               1.0            0.8            NaN            NaN   \n",
       "1553               0.8            NaN            NaN            NaN   \n",
       "1840               0.8            0.8            NaN            NaN   \n",
       "1917               0.8            NaN            1.0            1.0   \n",
       "1936               NaN            1.0            NaN            NaN   \n",
       "1959               NaN            1.0            NaN            NaN   \n",
       "2763               1.0            NaN            NaN            NaN   \n",
       "2973               NaN            NaN            NaN            NaN   \n",
       "3449               NaN            NaN            1.0            NaN   \n",
       "3472               1.0            0.8            NaN            NaN   \n",
       "3553               0.8            NaN            NaN            NaN   \n",
       "3646               0.8            0.6            0.8            NaN   \n",
       "3700               1.0            NaN            NaN            NaN   \n",
       "3747               NaN            NaN            NaN            NaN   \n",
       "4005               0.8            0.8            NaN            NaN   \n",
       "\n",
       "ISBN     9789579447607  9789866712982  9789866739798  9789866954108  \\\n",
       "user_id                                                               \n",
       "195                NaN            NaN            0.4            NaN   \n",
       "952                NaN            NaN            NaN            NaN   \n",
       "1103               NaN            NaN            NaN            NaN   \n",
       "1314               NaN            NaN            NaN            0.8   \n",
       "1492               NaN            1.0            NaN            NaN   \n",
       "1553               NaN            NaN            NaN            NaN   \n",
       "1840               NaN            NaN            NaN            0.6   \n",
       "1917               1.0            NaN            NaN            NaN   \n",
       "1936               NaN            1.0            0.8            NaN   \n",
       "1959               NaN            NaN            0.6            1.0   \n",
       "2763               NaN            NaN            NaN            1.0   \n",
       "2973               NaN            NaN            NaN            0.8   \n",
       "3449               NaN            NaN            NaN            0.8   \n",
       "3472               NaN            NaN            0.6            NaN   \n",
       "3553               NaN            NaN            0.0            0.6   \n",
       "3646               NaN            NaN            NaN            0.6   \n",
       "3700               NaN            NaN            NaN            NaN   \n",
       "3747               NaN            NaN            NaN            NaN   \n",
       "4005               NaN            0.8            NaN            0.8   \n",
       "\n",
       "ISBN     9789866973420  9789867778383  9789868461406  9789868652378  \\\n",
       "user_id                                                               \n",
       "195                0.6            NaN            1.0            0.8   \n",
       "952                NaN            NaN            NaN            NaN   \n",
       "1103               0.8            NaN            1.0            0.8   \n",
       "1314               1.0            NaN            0.8            0.8   \n",
       "1492               1.0            NaN            0.8            0.8   \n",
       "1553               NaN            NaN            NaN            0.6   \n",
       "1840               NaN            NaN            0.6            0.8   \n",
       "1917               NaN            NaN            NaN            NaN   \n",
       "1936               NaN            NaN            1.0            NaN   \n",
       "1959               NaN            NaN            NaN            0.8   \n",
       "2763               NaN            NaN            1.0            0.8   \n",
       "2973               NaN            NaN            NaN            NaN   \n",
       "3449               NaN            0.8            NaN            NaN   \n",
       "3472               NaN            NaN            NaN            1.0   \n",
       "3553               NaN            NaN            0.8            0.6   \n",
       "3646               NaN            NaN            NaN            0.6   \n",
       "3700               NaN            NaN            NaN            NaN   \n",
       "3747               NaN            NaN            NaN            NaN   \n",
       "4005               NaN            NaN            NaN            NaN   \n",
       "\n",
       "ISBN     9789868703612  9789868781900  9789869236478  \n",
       "user_id                                               \n",
       "195                NaN            NaN            NaN  \n",
       "952                0.6            NaN            0.8  \n",
       "1103               NaN            NaN            NaN  \n",
       "1314               0.8            NaN            NaN  \n",
       "1492               0.8            0.0            NaN  \n",
       "1553               NaN            NaN            NaN  \n",
       "1840               NaN            NaN            NaN  \n",
       "1917               NaN            NaN            NaN  \n",
       "1936               NaN            NaN            NaN  \n",
       "1959               0.8            1.0            NaN  \n",
       "2763               NaN            NaN            NaN  \n",
       "2973               NaN            NaN            NaN  \n",
       "3449               NaN            NaN            NaN  \n",
       "3472               NaN            NaN            NaN  \n",
       "3553               NaN            NaN            NaN  \n",
       "3646               0.8            1.0            0.8  \n",
       "3700               0.8            NaN            NaN  \n",
       "3747               NaN            1.0            NaN  \n",
       "4005               0.8            NaN            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = rating_df.groupby('user_id')['USERSTAR'].count()\n",
    "top_users = g.dropna().sort_values(ascending=False)[:20]\n",
    "top_r = rating_df.join(top_users, rsuffix='_r', how='inner', on='user_id')\n",
    "\n",
    "g = rating_df.groupby('ISBN')['USERSTAR'].count()\n",
    "top_ISBN = g.dropna().sort_values(ascending=False)[:20]\n",
    "top_r = top_r.join(top_ISBN, rsuffix='_r', how='inner', on='ISBN')\n",
    "\n",
    "pd.crosstab(top_r.user_id, top_r.ISBN, top_r.USERSTAR, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6632e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of users: 4080, Num of ISBN: 46053\n",
      "Min STAR: 0.0, Max STAR: 1.0\n"
     ]
    }
   ],
   "source": [
    "user_ids = rating_df[\"user_id\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "user_encoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "rating_df[\"user\"] = rating_df[\"user_id\"].map(user2user_encoded)\n",
    "n_users = len(user2user_encoded)\n",
    "\n",
    "ISBN_ids = rating_df[\"ISBN\"].unique().tolist()\n",
    "ISBN2ISBN_encoded = {x: i for i, x in enumerate(ISBN_ids)}\n",
    "ISBN_encoded2ISBN = {i: x for i, x in enumerate(ISBN_ids)}\n",
    "rating_df[\"ISBN\"] = rating_df[\"ISBN\"].map(ISBN2ISBN_encoded)\n",
    "n_ISBN = len(ISBN2ISBN_encoded)\n",
    "\n",
    "print(\"Num of users: {}, Num of ISBN: {}\".format(n_users, n_ISBN))\n",
    "print(\"Min STAR: {}, Max STAR: {}\".format(min(rating_df['USERSTAR']), max(rating_df['USERSTAR'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93b4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = rating_df.sample(frac=1, random_state=73)\n",
    "\n",
    "X = rating_df[['user', 'ISBN']].values\n",
    "y = rating_df[\"USERSTAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8bdbfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Train set ratings: 85074\n",
      "> Test set ratings: 10000\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "test_set_size = 10000 #10k for test set\n",
    "train_indices = rating_df.shape[0] - test_set_size \n",
    "\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    X[:train_indices],\n",
    "    X[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")\n",
    "\n",
    "print('> Train set ratings: {}'.format(len(y_train)))\n",
    "print('> Test set ratings: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ee4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a01a6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f18ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers \n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "955a8267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ISBN (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 128)       522240      user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "ISBN_embedding (Embedding)      (None, 1, 128)       5894784     ISBN[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           user_embedding[0][0]             \n",
      "                                                                 ISBN_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1)            4           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 6,417,030\n",
      "Trainable params: 6,417,028\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n",
    "\n",
    "def RecommenderNet():\n",
    "    embedding_size = 128\n",
    "    \n",
    "    user = Input(name = 'user', shape = [1])\n",
    "    user_embedding = Embedding(name = 'user_embedding',\n",
    "                       input_dim = n_users, \n",
    "                       output_dim = embedding_size)(user)\n",
    "    \n",
    "    ISBN = Input(name = 'ISBN', shape = [1])\n",
    "    ISBN_embedding = Embedding(name = 'ISBN_embedding',\n",
    "                       input_dim = n_ISBN, \n",
    "                       output_dim = embedding_size)(ISBN)\n",
    "    \n",
    "    #x = Concatenate()([user_embedding, ISBN_embedding])\n",
    "    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, ISBN_embedding])\n",
    "    x = Flatten()(x)\n",
    "        \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=[user, ISBN], outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='Adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = RecommenderNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139c406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "start_lr = 0.00001\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.00005\n",
    "batch_size = 10000\n",
    "\n",
    "\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < rampup_epochs:\n",
    "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "    elif epoch < rampup_epochs + sustain_epochs:\n",
    "        return max_lr\n",
    "    else:\n",
    "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "\n",
    "\n",
    "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n",
    "\n",
    "checkpoint_filepath = './weights.h5'\n",
    "\n",
    "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                        save_weights_only=True,\n",
    "                                        monitor='val_loss',\n",
    "                                        mode='min',\n",
    "                                        save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 3, monitor='val_loss', \n",
    "                               mode='min', restore_best_weights=True)\n",
    "\n",
    "my_callbacks = [\n",
    "    model_checkpoints,\n",
    "    lr_callback,\n",
    "    early_stopping,   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de125540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "9/9 [==============================] - 3s 163ms/step - loss: 0.7326 - mae: 0.3461 - mse: 0.1569 - val_loss: 0.6931 - val_mae: 0.3382 - val_mse: 0.1397\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.7310 - mae: 0.3455 - mse: 0.1562 - val_loss: 0.6930 - val_mae: 0.3382 - val_mse: 0.1397\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.7287 - mae: 0.3445 - mse: 0.1551 - val_loss: 0.6930 - val_mae: 0.3381 - val_mse: 0.1397\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.7255 - mae: 0.3432 - mse: 0.1536 - val_loss: 0.6929 - val_mae: 0.3381 - val_mse: 0.1397\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 0.7214 - mae: 0.3416 - mse: 0.1517 - val_loss: 0.6929 - val_mae: 0.3380 - val_mse: 0.1396\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 0.7164 - mae: 0.3396 - mse: 0.1494 - val_loss: 0.6928 - val_mae: 0.3379 - val_mse: 0.1396\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 0.7112 - mae: 0.3375 - mse: 0.1470 - val_loss: 0.6927 - val_mae: 0.3379 - val_mse: 0.1395\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.7070 - mae: 0.3358 - mse: 0.1450 - val_loss: 0.6926 - val_mae: 0.3378 - val_mse: 0.1395\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 1s 127ms/step - loss: 0.7034 - mae: 0.3343 - mse: 0.1434 - val_loss: 0.6926 - val_mae: 0.3378 - val_mse: 0.1395\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 0.7004 - mae: 0.3331 - mse: 0.1420 - val_loss: 0.6926 - val_mae: 0.3377 - val_mse: 0.1395\n",
      "Epoch 11/15\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 0.6978 - mae: 0.3321 - mse: 0.1408 - val_loss: 0.6925 - val_mae: 0.3377 - val_mse: 0.1394\n",
      "Epoch 12/15\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.6955 - mae: 0.3311 - mse: 0.1397 - val_loss: 0.6925 - val_mae: 0.3377 - val_mse: 0.1394\n",
      "Epoch 13/15\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 0.6935 - mae: 0.3303 - mse: 0.1388 - val_loss: 0.6925 - val_mae: 0.3377 - val_mse: 0.1394\n",
      "Epoch 14/15\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 0.6918 - mae: 0.3296 - mse: 0.1380 - val_loss: 0.6925 - val_mae: 0.3376 - val_mse: 0.1394\n",
      "Epoch 15/15\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.6902 - mae: 0.3290 - mse: 0.1372 - val_loss: 0.6925 - val_mae: 0.3376 - val_mse: 0.1394\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "history = model.fit(\n",
    "    x=X_train_array,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=15,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_array, y_test),\n",
    "    callbacks=my_callbacks\n",
    ")\n",
    "\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff97ed35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history[\"loss\"][0:-2])\n",
    "plt.plot(history.history[\"val_loss\"][0:-2])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130c698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(name, model):\n",
    "    weight_layer = model.get_layer(name)\n",
    "    weights = weight_layer.get_weights()[0]\n",
    "    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n",
    "    return weights\n",
    "\n",
    "anime_weights = extract_weights('ISBN_embedding', model)\n",
    "user_weights = extract_weights('user_embedding', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3feb4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./categ.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "824fdd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fixing Names\n",
    "# def getAnimeName(ISBN_id):\n",
    "#     try:\n",
    "#         name = df[df.ISBN_id == ISBN_id].eng_version.values[0]\n",
    "#         if name is np.nan:\n",
    "#             name = df[df.ISBN_id == ISBN_id].Name.values[0]\n",
    "#     except:\n",
    "#         print('error')\n",
    "    \n",
    "#     return name\n",
    "\n",
    "# df['ISBN_id'] = df['ISBN']\n",
    "# df[\"eng_version\"] = df['書名']\n",
    "# df['eng_version'] = df.ISBN_id.apply(lambda x: getAnimeName(x))\n",
    "\n",
    "# df.sort_values(by=['Score'], \n",
    "#                inplace=True,\n",
    "#                ascending=False, \n",
    "#                kind='quicksort',\n",
    "#                na_position='last')\n",
    "\n",
    "# df = df[[\"ISBN_id\", \"eng_version\"]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
